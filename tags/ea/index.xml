<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>EA on Learning is living</title><link>https://krawczuk.eu/tags/ea/</link><description>Recent content in EA on Learning is living</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Mon, 27 Aug 2018 22:41:40 +0200</lastBuildDate><atom:link href="https://krawczuk.eu/tags/ea/index.xml" rel="self" type="application/rss+xml"/><item><title>Power and necessity of imperfection</title><link>https://krawczuk.eu/blog/powerandnecessityofimperfection/</link><pubDate>Mon, 27 Aug 2018 22:41:40 +0200</pubDate><guid>https://krawczuk.eu/blog/powerandnecessityofimperfection/</guid><description>I wrote a two part blog post trying to give people an intuitive feel on how much heuristics and approximation matters and how this connects to my opinions about AGI/superintelligence risk.
I&amp;rsquo;m not totally happy with the second part where I try for the first time to condense thoughts that have been swirling around my head for a while now, but hey, I can always rewrite it. I&amp;rsquo;m sure the internet would never be vicious to me about not getting things perfect on the first try.</description></item></channel></rss>