<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Learning is living</title><link>https://krawczuk.eu/</link><description>Recent content in Home on Learning is living</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><lastBuildDate>Thu, 14 Sep 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://krawczuk.eu/index.xml" rel="self" type="application/rss+xml"/><item><title>Power and necessity of imperfection</title><link>https://krawczuk.eu/blog/powerandnecessityofimperfection/</link><pubDate>Mon, 27 Aug 2018 22:41:40 +0200</pubDate><guid>https://krawczuk.eu/blog/powerandnecessityofimperfection/</guid><description>I wrote a two part blog post trying to give people an intuitive feel on how much heuristics and approximation matters and how this connects to my opinions about AGI/superintelligence risk.
I&amp;rsquo;m not totally happy with the second part where I try for the first time to condense thoughts that have been swirling around my head for a while now, but hey, I can always rewrite it. I&amp;rsquo;m sure the internet would never be vicious to me about not getting things perfect on the first try.</description></item><item><title>Three parts about anxiety</title><link>https://krawczuk.eu/article/threepartsonanxiety/</link><pubDate>Mon, 27 Aug 2018 20:31:03 +0200</pubDate><guid>https://krawczuk.eu/article/threepartsonanxiety/</guid><description>Anxiety is a complex thing. Part of its complexity is a discrepancy between what we call anxiety and how we seem to experience anxiety. The emotion itself is well defined and doesn&amp;rsquo;t sound that debilitating (at least if you don&amp;rsquo;t have an anxiety &amp;ldquo;disorder&amp;rdquo; (APA) or &amp;ldquo;medical&amp;rdquo; anxiety(MW) which most people don&amp;rsquo;t want to think of themselves). But if we look at the urban dictionary definitions, the language used is much stronger than that of the APA, or the Merriam Webster.</description></item><item><title>My Position on AI Risk and superintelligence</title><link>https://krawczuk.eu/opinion/mypositiononairisk/</link><pubDate>Tue, 17 Apr 2018 08:27:59 +0000</pubDate><guid>https://krawczuk.eu/opinion/mypositiononairisk/</guid><description>&amp;hellip;can be best summarized by this xkcd and this keynote by Charles Stross. Maciej Ceg≈Çowski also has some good stuff.
In my own words: I think AGI risk in the sense of alignment and controllability is an interesting field of research, but I also think that alignment is identical or smaller than the problem of governance in politics control is identical or smaller than the problem of controllability of agent based optimization algorithms, two examples being society and capitalism superintelligence is a red herring, human misuse of AI is a problem Why do I think that superintelligence/AGI is not a problem?</description></item><item><title>autotester</title><link>https://krawczuk.eu/project/autotester/</link><pubDate>Wed, 28 Sep 2016 00:00:00 +0000</pubDate><guid>https://krawczuk.eu/project/autotester/</guid><description>Building on agilentpyvisa, this is an attempt to create an extensible bot framework that can automate device characterization.</description></item><item><title>agilentpyvisa</title><link>https://krawczuk.eu/project/agilentpyvisa/</link><pubDate>Tue, 14 Jun 2016 00:00:00 +0000</pubDate><guid>https://krawczuk.eu/project/agilentpyvisa/</guid><description>In order to ease my testing and characterization life, I am hacking on a simple control library for VISA devices.</description></item></channel></rss>